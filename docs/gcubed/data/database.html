<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>gcubed.data.database API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>gcubed.data.database</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># ------------------------------------------------------------------
# Purpose: Manage loading and provision of the database.
# Author: Geoff Shuetrim
# ------------------------------------------------------------------

from __future__ import annotations
import logging
from operator import index
import os
import pandas as pd
import numpy as np
from gcubed.base import Base
import gcubed.constants as CONSTANTS
from gcubed.model_configuration import ModelConfiguration
from gcubed.sym_data import SymData


class Database(Base):
    &#34;&#34;&#34;

    The database class is used directly but it is also 
    subclassed to support specific data usage scenarios.

    It encapsulates all of the information about the database 
    of values for all variables across a range of years.
    
    &#34;&#34;&#34;

    def __init__(self, sym_data: SymData) -&gt; None:

        assert sym_data is not None
        assert isinstance(sym_data, SymData)
        self._sym_data = sym_data
        self._base_year = self.configuration.base_year
        logging.info(f&#34;Loading a database from {self.configuration.database_file}&#34;)
        self.__load_data()
        self.__validate()

    @property
    def sym_data(self) -&gt; SymData:
        &#34;&#34;&#34;
        The SYM processor output
        &#34;&#34;&#34;
        return self._sym_data

    @property
    def configuration(self) -&gt; ModelConfiguration:
        &#34;&#34;&#34;
        The model configuration
        &#34;&#34;&#34;
        return self.sym_data.configuration

    @property
    def variables(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Metadata about the variables, contained in a dataframe 
        with columns for each type of metadata and with the rows indexed by variable&#34;&#34;&#34;
        return self._variables

    @property
    def data(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        The data itself, contained in a dataframe with columns 
        indexed by 4 digit (YYYY) year strings and with the rows indexed by variable
        names.

        &#34;&#34;&#34;
        return self._data

    @property
    def variables_count(self) -&gt; int:
        &#34;&#34;&#34;
        The number of variables in the database.
        &#34;&#34;&#34;
        return len(self.variables.index)

    @property
    def years_count(self) -&gt; int:
        &#34;&#34;&#34;
        The number of years in the database.
        &#34;&#34;&#34;
        return len(self.data.columns)

    @property
    def years_column_names(self) -&gt; pd.Index:
        &#34;&#34;&#34;
        The year column names for the data.
        &#34;&#34;&#34;
        return self.data.columns

    @property
    def base_year(self) -&gt; int:
        &#34;&#34;&#34;
        The (YYYY) format base year for the data. All indexes in the database
        are based in the specified year.  Databases (but not database subclasses)
        can be rebased to different years.
        &#34;&#34;&#34;
        return self._base_year

    def __load_data(self):
        &#34;&#34;&#34;
        ### Overview

        Import the data from the database CSV file, splitting it into 
        the variable metadata and the data itself.
        &#34;&#34;&#34;
        filename = self.configuration.database_file
        assert os.path.isfile(filename)
        (self._variables, self._data) = self.load_data(filename)
        self._data = self._data.astype(float)
        self._variables.columns = (&#34;order&#34;, &#34;name&#34;, &#34;description&#34;, &#34;units&#34;, &#34;region&#34;)
        self._variables[&#34;order&#34;].astype(&#34;int&#34;)

    def __validate(self):
        &#34;&#34;&#34;        
        Raise an exception if the calibration data is invalid.

        TODO: Add check that the variable units match the units listed in the sym_data summary.
        &#34;&#34;&#34;
        assert len(self._variables.columns) == 5
        assert self.data is not None
        assert self.variables is not None
        assert self.years_count &gt; 0
        assert self.variables_count &gt; 0
        self.__validate_base_year()

    def __validate_base_year(self):
        &#34;&#34;&#34;
        Make sure that the price index is equal to zero for all regions, in the base year.
        &#34;&#34;&#34;
        assert self.data.loc[self.data.index.str.contains(CONSTANTS.PRID_PREFIX), str(self.base_year)].sum() == 0

    def export_to_csv(self, filename:str):
        &#34;&#34;&#34;
        Export the database to a CSV file, making sure that the file extension is &#39;.csv&#39;.
        &#34;&#34;&#34;
        if filename.endswith(&#39;.csv&#39;):
            np.savetxt(filename,self.data, delimiter=&#34;,&#34;)                
        else:
            np.savetxt(f&#34;{filename}.csv&#34;, self.data, delimiter=&#34;,&#34;)

    def rebase(self, new_base_year: int):
        &#34;&#34;&#34;
        Rebase a database so indices have a new base year.
        This can be used to convert the database used for calibration
        to a database with the base year equal to the start year
        for projections (eg. 2011 to 2018).

        Note that this script draws on the approach in the G-Cubed utilities/rebase.ox script.

       ### Arguments
            new_base_year (int): a YYYY formatted new base year for the database.
        &#34;&#34;&#34;

        # Adjust the price indices
        for prefix in CONSTANTS.LOG_INDEX_PREFIXES:
            self.__rebase_log_index(variable_prefix=prefix,  new_base_year=new_base_year)
        for prefix in CONSTANTS.LAG_LOG_INDEX_PREFIXES:
            self.__rebase_log_index(variable_prefix=prefix,  new_base_year=new_base_year+1)
        for prefix in CONSTANTS.LEAD_LOG_INDEX_PREFIXES:
            self.__rebase_log_index(prefix, new_base_year=new_base_year-1)
        for prefix in CONSTANTS.INDEX_PREFIXES:
            self.__rebase_index(variable_prefix=prefix, new_base_year=new_base_year)

        # Adjust real GDP for the change in the base year.
        self.__rebase_real_gdp(new_base_year=new_base_year)

        # Store the current base year for this database after the rebasing.
        self._base_year = new_base_year

        # Check that the rebasing operation worked.
        self.__validate_base_year()


    def __rebase_log_index(self, variable_prefix: str, new_base_year: int):
        &#34;&#34;&#34;
        Does a log index rebase, changing the base year for the chosen variables.
        This can also be used for rebasing lead and lag price and wage indices
        by simply modifying the new_base_year appropriately, adding 1 for a lag
        variable and subtracting 1 for a lead variable.
       ### Arguments
            variablePrefix: The text name of the variable to be rebased, up to
            but not including the component of the variable name in round brackets ().
            new_base_year: the new year to be applied in the output file, again in YYYY integer format
        &#34;&#34;&#34;
        row_indices = self.data.index.str.startswith(f&#34;{variable_prefix}(&#34;)
        data_for_variable: pd.DataFrame = self.data.loc[row_indices, :]
        self.data.loc[row_indices, :] = data_for_variable.sub(data_for_variable.loc[:, str(new_base_year)], axis=0)

    def __rebase_index(self, variable_prefix: str, new_base_year: int):
        &#34;&#34;&#34;
        Does an index rebase, changing the base year for the chosen variables.
        This can also be used for rebasing lead and lag indices
        by simply modifying the new_base_year appropriately, adding 1 for a lag
        variable and subtracting 1 for a lead variable.
       ### Arguments
            variablePrefix: The text name of the variable to be rebased, up to
            but not including the component of the variable name in round brackets ().
            new_base_year: the new year to be applied in the output file, again in YYYY integer format
        &#34;&#34;&#34;
        row_indices = self.data.index.str.startswith(f&#34;{variable_prefix}(&#34;)
        data_for_variable: pd.DataFrame = self.data.loc[row_indices, :]
        self.data.loc[row_indices, :] = 100 * data_for_variable.div(data_for_variable.loc[:, str(new_base_year)], axis=0)

    def __rebase_real_gdp(self, new_base_year: int):
        &#34;&#34;&#34;
        Does an index rebase, changing the base year for real GDP in each region.
        This updates the LGDPR and YRATR variables.

       ### Arguments
            new_base_year (int): the new year to be applied 
            in the output file, in YYYY integer format
        &#34;&#34;&#34;
        real_gdp_row_indices = self.data.index.str.startswith(f&#34;{CONSTANTS.REAL_GDP_PREFIX}(&#34;)
        real_gdp = self.data.loc[real_gdp_row_indices, :]
        nominal_gdp_row_indices = self.data.index.str.startswith(f&#34;{CONSTANTS.NOMINAL_GDP_PREFIX}(&#34;)
        nominal_gdp = self.data.loc[nominal_gdp_row_indices, :]
        scale_factor = nominal_gdp.loc[:, str(new_base_year)].to_numpy() / real_gdp.loc[:, str(new_base_year)].to_numpy()
        rebased_real_gdp: np.ndarray = real_gdp.to_numpy() * scale_factor.reshape((len(scale_factor), 1))
        self.data.loc[real_gdp_row_indices, :] = rebased_real_gdp

        rebased_real_gdp_ratio: np.ndarray = 100 * rebased_real_gdp / rebased_real_gdp[0,:]
        yratr_row_indices = self.data.index.str.startswith(f&#34;{CONSTANTS.US_REAL_GDP_RATIO_PREFIX}(&#34;)
        self.data.loc[yratr_row_indices, :] = rebased_real_gdp_ratio

    def rhs_vector_value(self, vector_name: str, year: int, use_neutral_real_interest_rate=False) -&gt; np.ndarray:
        &#34;&#34;&#34;

        ### Overview

        Retrieves data from the database for all of the variables in a specific RHS vector in the model.
        The data is retrieved for the specified year. 
        
        Note that some state variables have their data retrieved
        for the following year. 

        Note also that interest rate values can be overridden by the globally defined neutral real interest rate
        that is set in the model configuration file.

        The implementation steps are:

        1. get the rows for the variables of the given type in varmap.
        2. get the names of the variables in those rows from varmap.
        3. use those names to select the data from the calibration year database.
        4. set the values for those variables in the appropriate places in the vector to that data for that year
        using the indices specified in the varmap data.


       ### Arguments

        `vector_name`: The name of the vector to get the values for. This must be a RHS vector listed in
        the model&#39;s RHS vector names by the SymData class.

        `year`: The YYYY format year to get data for when populating the RHS vectors.
        e.g. 2011 implies linearise model equations around the values
        of the model variables in 2011 (or in adjacent years for leads/lags).

        `use_neutral_real_interest_rate`: True if interest rates are to be overridden with the
        model configuration neutral real interest rate and False otherwise.

       ### Returns
          
        A column vector with the requested values for the RHS vector or
        `None` if the vector has zero length.

        &#34;&#34;&#34;

        if not vector_name in self.sym_data.rhs_vector_names:
            raise Exception(f&#34;{vector_name} is not a RHS vector in the model. It should be one of {self.sym_data.rhs_vector_names}&#34;)

        vector_value: np.ndarray = np.zeros(shape=(self.sym_data.vector_length(vector_name=vector_name), 1), dtype=float)
        match vector_name:
            case &#34;exo&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;x1r&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
                vector_value[indices] = data
                for variable_prefix in CONSTANTS.STATE_LEAD_VARIABLES:
                    (sequence, data) = self.get_data_and_varmap_indices_for_matching_variables(variable_prefix=variable_prefix, vector_name=vector_name, year=year)
                    vector_value[sequence] = data

            case &#34;yxr&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data
                for variable_prefix in CONSTANTS.STATE_LEAD_VARIABLES:
                    (sequence, data) = self.get_data_and_varmap_indices_for_matching_variables(variable_prefix=variable_prefix, vector_name=vector_name, year=(year-1))
                    vector_value[sequence] = data

            case &#34;j1r&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
                vector_value[indices] = data

            case &#34;yjr&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;zer&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;exz&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
                vector_value[indices] = data

            case &#34;z1r&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;_&#34;:
                raise Exception(f&#34;Invalid RHS vector name {vector_name}.&#34;)

        # Replace all actual interest rate values with r0 parameter value for regions.
        if use_neutral_real_interest_rate:
            neutral_real_interest_rate: float = self.configuration.neutral_real_interest_rate
            var_type = self.sym_data.varmap_variable_type(vector_name)
            for prefix in CONSTANTS.INTEREST_RATE_PREFIXES:
                vector_rows_in_map = self.sym_data.var_map.var_type == var_type
                variable_rows_in_map = self.sym_data.var_map.name.str.startswith(f&#34;{prefix}(&#34;)
                rows_in_map = (vector_rows_in_map &amp; variable_rows_in_map)
                sequences:pd.DataFrame = self.sym_data.var_map.loc[rows_in_map, [&#34;sequence&#34;]]
                if not sequences.empty:
                    vector_value[sequences] = neutral_real_interest_rate

        return vector_value

    def get_data_and_varmap_indices(self, vector_name: str, year: int) -&gt; tuple:
        &#34;&#34;&#34;
       ### Arguments

        vector_name: The three character name of the vector that is to be populated 
        with data.

        year: the 4 digit integer specifying the year in the database that will be used
        to source the data that will be inserted into the named vector.

        This method uses the varmap file created by the SYM processor, 
        finding those rows in the varmap that have a value in the var_type column 
        that match the given vector_name, e.g. &#39;x1r&#39;.
        The matching rows contain the variable names and their indices within the
        vector that has been named as an input to the function.

        The variable names are used to determine the rows of the database where the
        data will be sourced.

        The year determines the column in the database where the data will be sourced.

        A tuple is returned. That tuple contains a numpy vector of the data that has been 
        extracted from the database and a vector of indices indicating where, in the specified
        vector, that data should be inserted.

        &#34;&#34;&#34;
        variable_type:str = self.sym_data.varmap_variable_type(vector_name=vector_name)
        map = self.sym_data.var_map[self.sym_data.var_map.var_type == variable_type]
        
        names = map.name
        indices = map.sequence
        result: np.ndarray = self.data.loc[names, str(year)].to_numpy()
        return (result.reshape((len(result), 1)), indices)

    def get_data_and_varmap_indices_for_matching_variables(self, variable_prefix: str, vector_name: str, year: int):
        &#34;&#34;&#34;
        Gets matching data for the given variable prefix for a given vector.

       ### Arguments

        variable_prefix: The prefix for the variable name

        vector_name: the name of the vector to be populated.

        Returns a tuple containing the indices in the vector to be populated (as a list of integers) 
        and the values to use to do the populating as a numpy column vector.
        &#34;&#34;&#34;
        map: pd.DataFrame = self.sym_data.var_map[self.sym_data.var_map[&#39;name&#39;].str.contains(variable_prefix)]

        variable_type:str = self.sym_data.varmap_variable_type(vector_name=vector_name)
        map = map[map.var_type.str.match(variable_type)]
        
        result: np.ndarray = self.data.loc[map.name, str(year)].to_numpy()

        return (map.sequence.to_list(), result.reshape((len(result), 1)))

    def get_data(self, name_regular_expression: str, years: list) -&gt; pd.DataFrame:
        &#34;&#34;&#34;

        Gets data for the set of variables with variable names that match the given regular
        expression.

       ### Arguments

        name_regular_expression (str): The variable selection criteria. It can be any 
        regular expression that works with the Python regex package. 
        
        To get select all variables with a name that starts with INF, use &#34;^INF&#34;.

        To get the specific variable, INFL(UU), use &#34;^INFL\(UU\)&#34;.

        To get the the INFL variables for all regions, use &#34;^INFL\(&#34;.

        years (list): the list of years for which the data is to be retrieved. Note that
        this can be a list of integer values or a list of strings.

       ### Returns
        
        pd.DataFrame: a copy of the data for the specified year for 
        all variables with names matching the given regular expression
        where the names are matched against the row index (labels) in 
        the database.
        &#34;&#34;&#34;
        selected_rows = self.data.index.str.contains(name_regular_expression)
        if not years:
            return self.data.loc[selected_rows, :].copy()
        if isinstance(years, int):
            return self.data.loc[selected_rows, [str(years)]].copy()
        if isinstance(years, str):
            return self.data.loc[selected_rows, [years]].copy()
        if isinstance(years, list):
            # works with list of integers or strings
            selected_columns = [str(x) for x in years]
            return self.data.loc[selected_rows, selected_columns].copy()
        raise Exception(
            f&#34;There is no data available matching {name_regular_expression} in {years}&#34;)

    def update_data(self, new_data: pd.DataFrame):
        &#34;&#34;&#34;
        Replace the existing data property with a new dataframe. All of the data is replaced.

        This is useful if you need to do projections and then treat those projections as actual data
        in a subsequent step in your analysis pipeline.

       ### Arguments

        new_data (pd.DataFrame): The new dataframe to use.
        &#34;&#34;&#34;
        if not self._data.index.equals(new_data.index):
            raise Exception(&#34;The new database does not describe the same set of variables as the old database.&#34;)
        self._data = new_data

    def has_data(self, year:int) -&gt; bool:
        &#34;&#34;&#34;
        Used to check if there is a column of data in the database for the specified year.

        Args:

        year (int): The 4 digit integer value of the year (YYYY).

       ### Returns
        bool:  True if the database has data for the specified year and False otherwise
        &#34;&#34;&#34;
        return str(year) in self.data.columns

    @property 
    def has_data_for_all_projection_years(self) -&gt; bool:
        &#34;&#34;&#34;
        This property is used when determining whether the database has been populated
        with projections, in which case those projections provide values, now stored 
        as data, out to the end year of the projections.

        bool: True if the database has data for the last projection year.
        &#34;&#34;&#34;
        return self.has_data(year = self.configuration.end_year)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="gcubed.data.database.Database"><code class="flex name class">
<span>class <span class="ident">Database</span></span>
<span>(</span><span>sym_data: SymData)</span>
</code></dt>
<dd>
<div class="desc"><p>The database class is used directly but it is also
subclassed to support specific data usage scenarios.</p>
<p>It encapsulates all of the information about the database
of values for all variables across a range of years.</p>
<h3 id="constructor">Constructor</h3>
<p>Does constructor operations required by all classes that inherit from this base class.</p>
<p>These currently just set up numpy array print options.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Database(Base):
    &#34;&#34;&#34;

    The database class is used directly but it is also 
    subclassed to support specific data usage scenarios.

    It encapsulates all of the information about the database 
    of values for all variables across a range of years.
    
    &#34;&#34;&#34;

    def __init__(self, sym_data: SymData) -&gt; None:

        assert sym_data is not None
        assert isinstance(sym_data, SymData)
        self._sym_data = sym_data
        self._base_year = self.configuration.base_year
        logging.info(f&#34;Loading a database from {self.configuration.database_file}&#34;)
        self.__load_data()
        self.__validate()

    @property
    def sym_data(self) -&gt; SymData:
        &#34;&#34;&#34;
        The SYM processor output
        &#34;&#34;&#34;
        return self._sym_data

    @property
    def configuration(self) -&gt; ModelConfiguration:
        &#34;&#34;&#34;
        The model configuration
        &#34;&#34;&#34;
        return self.sym_data.configuration

    @property
    def variables(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        Metadata about the variables, contained in a dataframe 
        with columns for each type of metadata and with the rows indexed by variable&#34;&#34;&#34;
        return self._variables

    @property
    def data(self) -&gt; pd.DataFrame:
        &#34;&#34;&#34;
        The data itself, contained in a dataframe with columns 
        indexed by 4 digit (YYYY) year strings and with the rows indexed by variable
        names.

        &#34;&#34;&#34;
        return self._data

    @property
    def variables_count(self) -&gt; int:
        &#34;&#34;&#34;
        The number of variables in the database.
        &#34;&#34;&#34;
        return len(self.variables.index)

    @property
    def years_count(self) -&gt; int:
        &#34;&#34;&#34;
        The number of years in the database.
        &#34;&#34;&#34;
        return len(self.data.columns)

    @property
    def years_column_names(self) -&gt; pd.Index:
        &#34;&#34;&#34;
        The year column names for the data.
        &#34;&#34;&#34;
        return self.data.columns

    @property
    def base_year(self) -&gt; int:
        &#34;&#34;&#34;
        The (YYYY) format base year for the data. All indexes in the database
        are based in the specified year.  Databases (but not database subclasses)
        can be rebased to different years.
        &#34;&#34;&#34;
        return self._base_year

    def __load_data(self):
        &#34;&#34;&#34;
        ### Overview

        Import the data from the database CSV file, splitting it into 
        the variable metadata and the data itself.
        &#34;&#34;&#34;
        filename = self.configuration.database_file
        assert os.path.isfile(filename)
        (self._variables, self._data) = self.load_data(filename)
        self._data = self._data.astype(float)
        self._variables.columns = (&#34;order&#34;, &#34;name&#34;, &#34;description&#34;, &#34;units&#34;, &#34;region&#34;)
        self._variables[&#34;order&#34;].astype(&#34;int&#34;)

    def __validate(self):
        &#34;&#34;&#34;        
        Raise an exception if the calibration data is invalid.

        TODO: Add check that the variable units match the units listed in the sym_data summary.
        &#34;&#34;&#34;
        assert len(self._variables.columns) == 5
        assert self.data is not None
        assert self.variables is not None
        assert self.years_count &gt; 0
        assert self.variables_count &gt; 0
        self.__validate_base_year()

    def __validate_base_year(self):
        &#34;&#34;&#34;
        Make sure that the price index is equal to zero for all regions, in the base year.
        &#34;&#34;&#34;
        assert self.data.loc[self.data.index.str.contains(CONSTANTS.PRID_PREFIX), str(self.base_year)].sum() == 0

    def export_to_csv(self, filename:str):
        &#34;&#34;&#34;
        Export the database to a CSV file, making sure that the file extension is &#39;.csv&#39;.
        &#34;&#34;&#34;
        if filename.endswith(&#39;.csv&#39;):
            np.savetxt(filename,self.data, delimiter=&#34;,&#34;)                
        else:
            np.savetxt(f&#34;{filename}.csv&#34;, self.data, delimiter=&#34;,&#34;)

    def rebase(self, new_base_year: int):
        &#34;&#34;&#34;
        Rebase a database so indices have a new base year.
        This can be used to convert the database used for calibration
        to a database with the base year equal to the start year
        for projections (eg. 2011 to 2018).

        Note that this script draws on the approach in the G-Cubed utilities/rebase.ox script.

       ### Arguments
            new_base_year (int): a YYYY formatted new base year for the database.
        &#34;&#34;&#34;

        # Adjust the price indices
        for prefix in CONSTANTS.LOG_INDEX_PREFIXES:
            self.__rebase_log_index(variable_prefix=prefix,  new_base_year=new_base_year)
        for prefix in CONSTANTS.LAG_LOG_INDEX_PREFIXES:
            self.__rebase_log_index(variable_prefix=prefix,  new_base_year=new_base_year+1)
        for prefix in CONSTANTS.LEAD_LOG_INDEX_PREFIXES:
            self.__rebase_log_index(prefix, new_base_year=new_base_year-1)
        for prefix in CONSTANTS.INDEX_PREFIXES:
            self.__rebase_index(variable_prefix=prefix, new_base_year=new_base_year)

        # Adjust real GDP for the change in the base year.
        self.__rebase_real_gdp(new_base_year=new_base_year)

        # Store the current base year for this database after the rebasing.
        self._base_year = new_base_year

        # Check that the rebasing operation worked.
        self.__validate_base_year()


    def __rebase_log_index(self, variable_prefix: str, new_base_year: int):
        &#34;&#34;&#34;
        Does a log index rebase, changing the base year for the chosen variables.
        This can also be used for rebasing lead and lag price and wage indices
        by simply modifying the new_base_year appropriately, adding 1 for a lag
        variable and subtracting 1 for a lead variable.
       ### Arguments
            variablePrefix: The text name of the variable to be rebased, up to
            but not including the component of the variable name in round brackets ().
            new_base_year: the new year to be applied in the output file, again in YYYY integer format
        &#34;&#34;&#34;
        row_indices = self.data.index.str.startswith(f&#34;{variable_prefix}(&#34;)
        data_for_variable: pd.DataFrame = self.data.loc[row_indices, :]
        self.data.loc[row_indices, :] = data_for_variable.sub(data_for_variable.loc[:, str(new_base_year)], axis=0)

    def __rebase_index(self, variable_prefix: str, new_base_year: int):
        &#34;&#34;&#34;
        Does an index rebase, changing the base year for the chosen variables.
        This can also be used for rebasing lead and lag indices
        by simply modifying the new_base_year appropriately, adding 1 for a lag
        variable and subtracting 1 for a lead variable.
       ### Arguments
            variablePrefix: The text name of the variable to be rebased, up to
            but not including the component of the variable name in round brackets ().
            new_base_year: the new year to be applied in the output file, again in YYYY integer format
        &#34;&#34;&#34;
        row_indices = self.data.index.str.startswith(f&#34;{variable_prefix}(&#34;)
        data_for_variable: pd.DataFrame = self.data.loc[row_indices, :]
        self.data.loc[row_indices, :] = 100 * data_for_variable.div(data_for_variable.loc[:, str(new_base_year)], axis=0)

    def __rebase_real_gdp(self, new_base_year: int):
        &#34;&#34;&#34;
        Does an index rebase, changing the base year for real GDP in each region.
        This updates the LGDPR and YRATR variables.

       ### Arguments
            new_base_year (int): the new year to be applied 
            in the output file, in YYYY integer format
        &#34;&#34;&#34;
        real_gdp_row_indices = self.data.index.str.startswith(f&#34;{CONSTANTS.REAL_GDP_PREFIX}(&#34;)
        real_gdp = self.data.loc[real_gdp_row_indices, :]
        nominal_gdp_row_indices = self.data.index.str.startswith(f&#34;{CONSTANTS.NOMINAL_GDP_PREFIX}(&#34;)
        nominal_gdp = self.data.loc[nominal_gdp_row_indices, :]
        scale_factor = nominal_gdp.loc[:, str(new_base_year)].to_numpy() / real_gdp.loc[:, str(new_base_year)].to_numpy()
        rebased_real_gdp: np.ndarray = real_gdp.to_numpy() * scale_factor.reshape((len(scale_factor), 1))
        self.data.loc[real_gdp_row_indices, :] = rebased_real_gdp

        rebased_real_gdp_ratio: np.ndarray = 100 * rebased_real_gdp / rebased_real_gdp[0,:]
        yratr_row_indices = self.data.index.str.startswith(f&#34;{CONSTANTS.US_REAL_GDP_RATIO_PREFIX}(&#34;)
        self.data.loc[yratr_row_indices, :] = rebased_real_gdp_ratio

    def rhs_vector_value(self, vector_name: str, year: int, use_neutral_real_interest_rate=False) -&gt; np.ndarray:
        &#34;&#34;&#34;

        ### Overview

        Retrieves data from the database for all of the variables in a specific RHS vector in the model.
        The data is retrieved for the specified year. 
        
        Note that some state variables have their data retrieved
        for the following year. 

        Note also that interest rate values can be overridden by the globally defined neutral real interest rate
        that is set in the model configuration file.

        The implementation steps are:

        1. get the rows for the variables of the given type in varmap.
        2. get the names of the variables in those rows from varmap.
        3. use those names to select the data from the calibration year database.
        4. set the values for those variables in the appropriate places in the vector to that data for that year
        using the indices specified in the varmap data.


       ### Arguments

        `vector_name`: The name of the vector to get the values for. This must be a RHS vector listed in
        the model&#39;s RHS vector names by the SymData class.

        `year`: The YYYY format year to get data for when populating the RHS vectors.
        e.g. 2011 implies linearise model equations around the values
        of the model variables in 2011 (or in adjacent years for leads/lags).

        `use_neutral_real_interest_rate`: True if interest rates are to be overridden with the
        model configuration neutral real interest rate and False otherwise.

       ### Returns
          
        A column vector with the requested values for the RHS vector or
        `None` if the vector has zero length.

        &#34;&#34;&#34;

        if not vector_name in self.sym_data.rhs_vector_names:
            raise Exception(f&#34;{vector_name} is not a RHS vector in the model. It should be one of {self.sym_data.rhs_vector_names}&#34;)

        vector_value: np.ndarray = np.zeros(shape=(self.sym_data.vector_length(vector_name=vector_name), 1), dtype=float)
        match vector_name:
            case &#34;exo&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;x1r&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
                vector_value[indices] = data
                for variable_prefix in CONSTANTS.STATE_LEAD_VARIABLES:
                    (sequence, data) = self.get_data_and_varmap_indices_for_matching_variables(variable_prefix=variable_prefix, vector_name=vector_name, year=year)
                    vector_value[sequence] = data

            case &#34;yxr&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data
                for variable_prefix in CONSTANTS.STATE_LEAD_VARIABLES:
                    (sequence, data) = self.get_data_and_varmap_indices_for_matching_variables(variable_prefix=variable_prefix, vector_name=vector_name, year=(year-1))
                    vector_value[sequence] = data

            case &#34;j1r&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
                vector_value[indices] = data

            case &#34;yjr&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;zer&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;exz&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
                vector_value[indices] = data

            case &#34;z1r&#34;:
                (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
                vector_value[indices] = data

            case &#34;_&#34;:
                raise Exception(f&#34;Invalid RHS vector name {vector_name}.&#34;)

        # Replace all actual interest rate values with r0 parameter value for regions.
        if use_neutral_real_interest_rate:
            neutral_real_interest_rate: float = self.configuration.neutral_real_interest_rate
            var_type = self.sym_data.varmap_variable_type(vector_name)
            for prefix in CONSTANTS.INTEREST_RATE_PREFIXES:
                vector_rows_in_map = self.sym_data.var_map.var_type == var_type
                variable_rows_in_map = self.sym_data.var_map.name.str.startswith(f&#34;{prefix}(&#34;)
                rows_in_map = (vector_rows_in_map &amp; variable_rows_in_map)
                sequences:pd.DataFrame = self.sym_data.var_map.loc[rows_in_map, [&#34;sequence&#34;]]
                if not sequences.empty:
                    vector_value[sequences] = neutral_real_interest_rate

        return vector_value

    def get_data_and_varmap_indices(self, vector_name: str, year: int) -&gt; tuple:
        &#34;&#34;&#34;
       ### Arguments

        vector_name: The three character name of the vector that is to be populated 
        with data.

        year: the 4 digit integer specifying the year in the database that will be used
        to source the data that will be inserted into the named vector.

        This method uses the varmap file created by the SYM processor, 
        finding those rows in the varmap that have a value in the var_type column 
        that match the given vector_name, e.g. &#39;x1r&#39;.
        The matching rows contain the variable names and their indices within the
        vector that has been named as an input to the function.

        The variable names are used to determine the rows of the database where the
        data will be sourced.

        The year determines the column in the database where the data will be sourced.

        A tuple is returned. That tuple contains a numpy vector of the data that has been 
        extracted from the database and a vector of indices indicating where, in the specified
        vector, that data should be inserted.

        &#34;&#34;&#34;
        variable_type:str = self.sym_data.varmap_variable_type(vector_name=vector_name)
        map = self.sym_data.var_map[self.sym_data.var_map.var_type == variable_type]
        
        names = map.name
        indices = map.sequence
        result: np.ndarray = self.data.loc[names, str(year)].to_numpy()
        return (result.reshape((len(result), 1)), indices)

    def get_data_and_varmap_indices_for_matching_variables(self, variable_prefix: str, vector_name: str, year: int):
        &#34;&#34;&#34;
        Gets matching data for the given variable prefix for a given vector.

       ### Arguments

        variable_prefix: The prefix for the variable name

        vector_name: the name of the vector to be populated.

        Returns a tuple containing the indices in the vector to be populated (as a list of integers) 
        and the values to use to do the populating as a numpy column vector.
        &#34;&#34;&#34;
        map: pd.DataFrame = self.sym_data.var_map[self.sym_data.var_map[&#39;name&#39;].str.contains(variable_prefix)]

        variable_type:str = self.sym_data.varmap_variable_type(vector_name=vector_name)
        map = map[map.var_type.str.match(variable_type)]
        
        result: np.ndarray = self.data.loc[map.name, str(year)].to_numpy()

        return (map.sequence.to_list(), result.reshape((len(result), 1)))

    def get_data(self, name_regular_expression: str, years: list) -&gt; pd.DataFrame:
        &#34;&#34;&#34;

        Gets data for the set of variables with variable names that match the given regular
        expression.

       ### Arguments

        name_regular_expression (str): The variable selection criteria. It can be any 
        regular expression that works with the Python regex package. 
        
        To get select all variables with a name that starts with INF, use &#34;^INF&#34;.

        To get the specific variable, INFL(UU), use &#34;^INFL\(UU\)&#34;.

        To get the the INFL variables for all regions, use &#34;^INFL\(&#34;.

        years (list): the list of years for which the data is to be retrieved. Note that
        this can be a list of integer values or a list of strings.

       ### Returns
        
        pd.DataFrame: a copy of the data for the specified year for 
        all variables with names matching the given regular expression
        where the names are matched against the row index (labels) in 
        the database.
        &#34;&#34;&#34;
        selected_rows = self.data.index.str.contains(name_regular_expression)
        if not years:
            return self.data.loc[selected_rows, :].copy()
        if isinstance(years, int):
            return self.data.loc[selected_rows, [str(years)]].copy()
        if isinstance(years, str):
            return self.data.loc[selected_rows, [years]].copy()
        if isinstance(years, list):
            # works with list of integers or strings
            selected_columns = [str(x) for x in years]
            return self.data.loc[selected_rows, selected_columns].copy()
        raise Exception(
            f&#34;There is no data available matching {name_regular_expression} in {years}&#34;)

    def update_data(self, new_data: pd.DataFrame):
        &#34;&#34;&#34;
        Replace the existing data property with a new dataframe. All of the data is replaced.

        This is useful if you need to do projections and then treat those projections as actual data
        in a subsequent step in your analysis pipeline.

       ### Arguments

        new_data (pd.DataFrame): The new dataframe to use.
        &#34;&#34;&#34;
        if not self._data.index.equals(new_data.index):
            raise Exception(&#34;The new database does not describe the same set of variables as the old database.&#34;)
        self._data = new_data

    def has_data(self, year:int) -&gt; bool:
        &#34;&#34;&#34;
        Used to check if there is a column of data in the database for the specified year.

        Args:

        year (int): The 4 digit integer value of the year (YYYY).

       ### Returns
        bool:  True if the database has data for the specified year and False otherwise
        &#34;&#34;&#34;
        return str(year) in self.data.columns

    @property 
    def has_data_for_all_projection_years(self) -&gt; bool:
        &#34;&#34;&#34;
        This property is used when determining whether the database has been populated
        with projections, in which case those projections provide values, now stored 
        as data, out to the end year of the projections.

        bool: True if the database has data for the last projection year.
        &#34;&#34;&#34;
        return self.has_data(year = self.configuration.end_year)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="gcubed.base.Base" href="../base.html#gcubed.base.Base">Base</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="gcubed.data.calibration_database.CalibrationDatabase" href="calibration_database.html#gcubed.data.calibration_database.CalibrationDatabase">CalibrationDatabase</a></li>
<li><a title="gcubed.data.gdp_scaled_database.GDPScaledDatabase" href="gdp_scaled_database.html#gcubed.data.gdp_scaled_database.GDPScaledDatabase">GDPScaledDatabase</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="gcubed.data.database.Database.base_year"><code class="name">var <span class="ident">base_year</span> : int</code></dt>
<dd>
<div class="desc"><p>The (YYYY) format base year for the data. All indexes in the database
are based in the specified year.
Databases (but not database subclasses)
can be rebased to different years.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def base_year(self) -&gt; int:
    &#34;&#34;&#34;
    The (YYYY) format base year for the data. All indexes in the database
    are based in the specified year.  Databases (but not database subclasses)
    can be rebased to different years.
    &#34;&#34;&#34;
    return self._base_year</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.configuration"><code class="name">var <span class="ident">configuration</span> : <a title="gcubed.model_configuration.ModelConfiguration" href="../model_configuration.html#gcubed.model_configuration.ModelConfiguration">ModelConfiguration</a></code></dt>
<dd>
<div class="desc"><p>The model configuration</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def configuration(self) -&gt; ModelConfiguration:
    &#34;&#34;&#34;
    The model configuration
    &#34;&#34;&#34;
    return self.sym_data.configuration</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.data"><code class="name">var <span class="ident">data</span> : pandas.core.frame.DataFrame</code></dt>
<dd>
<div class="desc"><p>The data itself, contained in a dataframe with columns
indexed by 4 digit (YYYY) year strings and with the rows indexed by variable
names.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def data(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    The data itself, contained in a dataframe with columns 
    indexed by 4 digit (YYYY) year strings and with the rows indexed by variable
    names.

    &#34;&#34;&#34;
    return self._data</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.has_data_for_all_projection_years"><code class="name">var <span class="ident">has_data_for_all_projection_years</span> : bool</code></dt>
<dd>
<div class="desc"><p>This property is used when determining whether the database has been populated
with projections, in which case those projections provide values, now stored
as data, out to the end year of the projections.</p>
<p>bool: True if the database has data for the last projection year.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property 
def has_data_for_all_projection_years(self) -&gt; bool:
    &#34;&#34;&#34;
    This property is used when determining whether the database has been populated
    with projections, in which case those projections provide values, now stored 
    as data, out to the end year of the projections.

    bool: True if the database has data for the last projection year.
    &#34;&#34;&#34;
    return self.has_data(year = self.configuration.end_year)</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.sym_data"><code class="name">var <span class="ident">sym_data</span> : <a title="gcubed.sym_data.SymData" href="../sym_data.html#gcubed.sym_data.SymData">SymData</a></code></dt>
<dd>
<div class="desc"><p>The SYM processor output</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def sym_data(self) -&gt; SymData:
    &#34;&#34;&#34;
    The SYM processor output
    &#34;&#34;&#34;
    return self._sym_data</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.variables"><code class="name">var <span class="ident">variables</span> : pandas.core.frame.DataFrame</code></dt>
<dd>
<div class="desc"><p>Metadata about the variables, contained in a dataframe
with columns for each type of metadata and with the rows indexed by variable</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def variables(self) -&gt; pd.DataFrame:
    &#34;&#34;&#34;
    Metadata about the variables, contained in a dataframe 
    with columns for each type of metadata and with the rows indexed by variable&#34;&#34;&#34;
    return self._variables</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.variables_count"><code class="name">var <span class="ident">variables_count</span> : int</code></dt>
<dd>
<div class="desc"><p>The number of variables in the database.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def variables_count(self) -&gt; int:
    &#34;&#34;&#34;
    The number of variables in the database.
    &#34;&#34;&#34;
    return len(self.variables.index)</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.years_column_names"><code class="name">var <span class="ident">years_column_names</span> : pandas.core.indexes.base.Index</code></dt>
<dd>
<div class="desc"><p>The year column names for the data.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def years_column_names(self) -&gt; pd.Index:
    &#34;&#34;&#34;
    The year column names for the data.
    &#34;&#34;&#34;
    return self.data.columns</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.years_count"><code class="name">var <span class="ident">years_count</span> : int</code></dt>
<dd>
<div class="desc"><p>The number of years in the database.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def years_count(self) -&gt; int:
    &#34;&#34;&#34;
    The number of years in the database.
    &#34;&#34;&#34;
    return len(self.data.columns)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="gcubed.data.database.Database.export_to_csv"><code class="name flex">
<span>def <span class="ident">export_to_csv</span></span>(<span>self, filename: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Export the database to a CSV file, making sure that the file extension is '.csv'.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export_to_csv(self, filename:str):
    &#34;&#34;&#34;
    Export the database to a CSV file, making sure that the file extension is &#39;.csv&#39;.
    &#34;&#34;&#34;
    if filename.endswith(&#39;.csv&#39;):
        np.savetxt(filename,self.data, delimiter=&#34;,&#34;)                
    else:
        np.savetxt(f&#34;{filename}.csv&#34;, self.data, delimiter=&#34;,&#34;)</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.get_data"><code class="name flex">
<span>def <span class="ident">get_data</span></span>(<span>self, name_regular_expression: str, years: list) ‑> pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Gets data for the set of variables with variable names that match the given regular
expression.</p>
<h3 id="arguments">Arguments</h3>
<p>name_regular_expression (str): The variable selection criteria. It can be any
regular expression that works with the Python regex package. </p>
<p>To get select all variables with a name that starts with INF, use "^INF".</p>
<p>To get the specific variable, INFL(UU), use "^INFL(UU)".</p>
<p>To get the the INFL variables for all regions, use "^INFL(".</p>
<p>years (list): the list of years for which the data is to be retrieved. Note that
this can be a list of integer values or a list of strings.</p>
<h3 id="returns">Returns</h3>
<p>pd.DataFrame: a copy of the data for the specified year for
all variables with names matching the given regular expression
where the names are matched against the row index (labels) in
the database.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data(self, name_regular_expression: str, years: list) -&gt; pd.DataFrame:
    &#34;&#34;&#34;

    Gets data for the set of variables with variable names that match the given regular
    expression.

   ### Arguments

    name_regular_expression (str): The variable selection criteria. It can be any 
    regular expression that works with the Python regex package. 
    
    To get select all variables with a name that starts with INF, use &#34;^INF&#34;.

    To get the specific variable, INFL(UU), use &#34;^INFL\(UU\)&#34;.

    To get the the INFL variables for all regions, use &#34;^INFL\(&#34;.

    years (list): the list of years for which the data is to be retrieved. Note that
    this can be a list of integer values or a list of strings.

   ### Returns
    
    pd.DataFrame: a copy of the data for the specified year for 
    all variables with names matching the given regular expression
    where the names are matched against the row index (labels) in 
    the database.
    &#34;&#34;&#34;
    selected_rows = self.data.index.str.contains(name_regular_expression)
    if not years:
        return self.data.loc[selected_rows, :].copy()
    if isinstance(years, int):
        return self.data.loc[selected_rows, [str(years)]].copy()
    if isinstance(years, str):
        return self.data.loc[selected_rows, [years]].copy()
    if isinstance(years, list):
        # works with list of integers or strings
        selected_columns = [str(x) for x in years]
        return self.data.loc[selected_rows, selected_columns].copy()
    raise Exception(
        f&#34;There is no data available matching {name_regular_expression} in {years}&#34;)</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.get_data_and_varmap_indices"><code class="name flex">
<span>def <span class="ident">get_data_and_varmap_indices</span></span>(<span>self, vector_name: str, year: int) ‑> tuple</span>
</code></dt>
<dd>
<div class="desc"><h3 id="arguments">Arguments</h3>
<p>vector_name: The three character name of the vector that is to be populated
with data.</p>
<p>year: the 4 digit integer specifying the year in the database that will be used
to source the data that will be inserted into the named vector.</p>
<p>This method uses the varmap file created by the SYM processor,
finding those rows in the varmap that have a value in the var_type column
that match the given vector_name, e.g. 'x1r'.
The matching rows contain the variable names and their indices within the
vector that has been named as an input to the function.</p>
<p>The variable names are used to determine the rows of the database where the
data will be sourced.</p>
<p>The year determines the column in the database where the data will be sourced.</p>
<p>A tuple is returned. That tuple contains a numpy vector of the data that has been
extracted from the database and a vector of indices indicating where, in the specified
vector, that data should be inserted.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data_and_varmap_indices(self, vector_name: str, year: int) -&gt; tuple:
    &#34;&#34;&#34;
   ### Arguments

    vector_name: The three character name of the vector that is to be populated 
    with data.

    year: the 4 digit integer specifying the year in the database that will be used
    to source the data that will be inserted into the named vector.

    This method uses the varmap file created by the SYM processor, 
    finding those rows in the varmap that have a value in the var_type column 
    that match the given vector_name, e.g. &#39;x1r&#39;.
    The matching rows contain the variable names and their indices within the
    vector that has been named as an input to the function.

    The variable names are used to determine the rows of the database where the
    data will be sourced.

    The year determines the column in the database where the data will be sourced.

    A tuple is returned. That tuple contains a numpy vector of the data that has been 
    extracted from the database and a vector of indices indicating where, in the specified
    vector, that data should be inserted.

    &#34;&#34;&#34;
    variable_type:str = self.sym_data.varmap_variable_type(vector_name=vector_name)
    map = self.sym_data.var_map[self.sym_data.var_map.var_type == variable_type]
    
    names = map.name
    indices = map.sequence
    result: np.ndarray = self.data.loc[names, str(year)].to_numpy()
    return (result.reshape((len(result), 1)), indices)</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.get_data_and_varmap_indices_for_matching_variables"><code class="name flex">
<span>def <span class="ident">get_data_and_varmap_indices_for_matching_variables</span></span>(<span>self, variable_prefix: str, vector_name: str, year: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets matching data for the given variable prefix for a given vector.</p>
<h3 id="arguments">Arguments</h3>
<p>variable_prefix: The prefix for the variable name</p>
<p>vector_name: the name of the vector to be populated.</p>
<p>Returns a tuple containing the indices in the vector to be populated (as a list of integers)
and the values to use to do the populating as a numpy column vector.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_data_and_varmap_indices_for_matching_variables(self, variable_prefix: str, vector_name: str, year: int):
    &#34;&#34;&#34;
    Gets matching data for the given variable prefix for a given vector.

   ### Arguments

    variable_prefix: The prefix for the variable name

    vector_name: the name of the vector to be populated.

    Returns a tuple containing the indices in the vector to be populated (as a list of integers) 
    and the values to use to do the populating as a numpy column vector.
    &#34;&#34;&#34;
    map: pd.DataFrame = self.sym_data.var_map[self.sym_data.var_map[&#39;name&#39;].str.contains(variable_prefix)]

    variable_type:str = self.sym_data.varmap_variable_type(vector_name=vector_name)
    map = map[map.var_type.str.match(variable_type)]
    
    result: np.ndarray = self.data.loc[map.name, str(year)].to_numpy()

    return (map.sequence.to_list(), result.reshape((len(result), 1)))</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.has_data"><code class="name flex">
<span>def <span class="ident">has_data</span></span>(<span>self, year: int) ‑> bool</span>
</code></dt>
<dd>
<div class="desc"><p>Used to check if there is a column of data in the database for the specified year.</p>
<p>Args:</p>
<p>year (int): The 4 digit integer value of the year (YYYY).</p>
<h3 id="returns">Returns</h3>
<p>bool:
True if the database has data for the specified year and False otherwise</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def has_data(self, year:int) -&gt; bool:
    &#34;&#34;&#34;
    Used to check if there is a column of data in the database for the specified year.

    Args:

    year (int): The 4 digit integer value of the year (YYYY).

   ### Returns
    bool:  True if the database has data for the specified year and False otherwise
    &#34;&#34;&#34;
    return str(year) in self.data.columns</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.rebase"><code class="name flex">
<span>def <span class="ident">rebase</span></span>(<span>self, new_base_year: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Rebase a database so indices have a new base year.
This can be used to convert the database used for calibration
to a database with the base year equal to the start year
for projections (eg. 2011 to 2018).</p>
<p>Note that this script draws on the approach in the G-Cubed utilities/rebase.ox script.</p>
<h3 id="arguments">Arguments</h3>
<pre><code> new_base_year (int): a YYYY formatted new base year for the database.
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rebase(self, new_base_year: int):
    &#34;&#34;&#34;
    Rebase a database so indices have a new base year.
    This can be used to convert the database used for calibration
    to a database with the base year equal to the start year
    for projections (eg. 2011 to 2018).

    Note that this script draws on the approach in the G-Cubed utilities/rebase.ox script.

   ### Arguments
        new_base_year (int): a YYYY formatted new base year for the database.
    &#34;&#34;&#34;

    # Adjust the price indices
    for prefix in CONSTANTS.LOG_INDEX_PREFIXES:
        self.__rebase_log_index(variable_prefix=prefix,  new_base_year=new_base_year)
    for prefix in CONSTANTS.LAG_LOG_INDEX_PREFIXES:
        self.__rebase_log_index(variable_prefix=prefix,  new_base_year=new_base_year+1)
    for prefix in CONSTANTS.LEAD_LOG_INDEX_PREFIXES:
        self.__rebase_log_index(prefix, new_base_year=new_base_year-1)
    for prefix in CONSTANTS.INDEX_PREFIXES:
        self.__rebase_index(variable_prefix=prefix, new_base_year=new_base_year)

    # Adjust real GDP for the change in the base year.
    self.__rebase_real_gdp(new_base_year=new_base_year)

    # Store the current base year for this database after the rebasing.
    self._base_year = new_base_year

    # Check that the rebasing operation worked.
    self.__validate_base_year()</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.rhs_vector_value"><code class="name flex">
<span>def <span class="ident">rhs_vector_value</span></span>(<span>self, vector_name: str, year: int, use_neutral_real_interest_rate=False) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><h3 id="overview">Overview</h3>
<p>Retrieves data from the database for all of the variables in a specific RHS vector in the model.
The data is retrieved for the specified year. </p>
<p>Note that some state variables have their data retrieved
for the following year. </p>
<p>Note also that interest rate values can be overridden by the globally defined neutral real interest rate
that is set in the model configuration file.</p>
<p>The implementation steps are:</p>
<ol>
<li>get the rows for the variables of the given type in varmap.</li>
<li>get the names of the variables in those rows from varmap.</li>
<li>use those names to select the data from the calibration year database.</li>
<li>set the values for those variables in the appropriate places in the vector to that data for that year
using the indices specified in the varmap data.</li>
</ol>
<h3 id="arguments">Arguments</h3>
<p><code>vector_name</code>: The name of the vector to get the values for. This must be a RHS vector listed in
the model's RHS vector names by the SymData class.</p>
<p><code>year</code>: The YYYY format year to get data for when populating the RHS vectors.
e.g. 2011 implies linearise model equations around the values
of the model variables in 2011 (or in adjacent years for leads/lags).</p>
<p><code>use_neutral_real_interest_rate</code>: True if interest rates are to be overridden with the
model configuration neutral real interest rate and False otherwise.</p>
<h3 id="returns">Returns</h3>
<p>A column vector with the requested values for the RHS vector or
<code>None</code> if the vector has zero length.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rhs_vector_value(self, vector_name: str, year: int, use_neutral_real_interest_rate=False) -&gt; np.ndarray:
    &#34;&#34;&#34;

    ### Overview

    Retrieves data from the database for all of the variables in a specific RHS vector in the model.
    The data is retrieved for the specified year. 
    
    Note that some state variables have their data retrieved
    for the following year. 

    Note also that interest rate values can be overridden by the globally defined neutral real interest rate
    that is set in the model configuration file.

    The implementation steps are:

    1. get the rows for the variables of the given type in varmap.
    2. get the names of the variables in those rows from varmap.
    3. use those names to select the data from the calibration year database.
    4. set the values for those variables in the appropriate places in the vector to that data for that year
    using the indices specified in the varmap data.


   ### Arguments

    `vector_name`: The name of the vector to get the values for. This must be a RHS vector listed in
    the model&#39;s RHS vector names by the SymData class.

    `year`: The YYYY format year to get data for when populating the RHS vectors.
    e.g. 2011 implies linearise model equations around the values
    of the model variables in 2011 (or in adjacent years for leads/lags).

    `use_neutral_real_interest_rate`: True if interest rates are to be overridden with the
    model configuration neutral real interest rate and False otherwise.

   ### Returns
      
    A column vector with the requested values for the RHS vector or
    `None` if the vector has zero length.

    &#34;&#34;&#34;

    if not vector_name in self.sym_data.rhs_vector_names:
        raise Exception(f&#34;{vector_name} is not a RHS vector in the model. It should be one of {self.sym_data.rhs_vector_names}&#34;)

    vector_value: np.ndarray = np.zeros(shape=(self.sym_data.vector_length(vector_name=vector_name), 1), dtype=float)
    match vector_name:
        case &#34;exo&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
            vector_value[indices] = data

        case &#34;x1r&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
            vector_value[indices] = data
            for variable_prefix in CONSTANTS.STATE_LEAD_VARIABLES:
                (sequence, data) = self.get_data_and_varmap_indices_for_matching_variables(variable_prefix=variable_prefix, vector_name=vector_name, year=year)
                vector_value[sequence] = data

        case &#34;yxr&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
            vector_value[indices] = data
            for variable_prefix in CONSTANTS.STATE_LEAD_VARIABLES:
                (sequence, data) = self.get_data_and_varmap_indices_for_matching_variables(variable_prefix=variable_prefix, vector_name=vector_name, year=(year-1))
                vector_value[sequence] = data

        case &#34;j1r&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
            vector_value[indices] = data

        case &#34;yjr&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
            vector_value[indices] = data

        case &#34;zer&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
            vector_value[indices] = data

        case &#34;exz&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=(year+1))
            vector_value[indices] = data

        case &#34;z1r&#34;:
            (data, indices) = self.get_data_and_varmap_indices(vector_name=vector_name, year=year)
            vector_value[indices] = data

        case &#34;_&#34;:
            raise Exception(f&#34;Invalid RHS vector name {vector_name}.&#34;)

    # Replace all actual interest rate values with r0 parameter value for regions.
    if use_neutral_real_interest_rate:
        neutral_real_interest_rate: float = self.configuration.neutral_real_interest_rate
        var_type = self.sym_data.varmap_variable_type(vector_name)
        for prefix in CONSTANTS.INTEREST_RATE_PREFIXES:
            vector_rows_in_map = self.sym_data.var_map.var_type == var_type
            variable_rows_in_map = self.sym_data.var_map.name.str.startswith(f&#34;{prefix}(&#34;)
            rows_in_map = (vector_rows_in_map &amp; variable_rows_in_map)
            sequences:pd.DataFrame = self.sym_data.var_map.loc[rows_in_map, [&#34;sequence&#34;]]
            if not sequences.empty:
                vector_value[sequences] = neutral_real_interest_rate

    return vector_value</code></pre>
</details>
</dd>
<dt id="gcubed.data.database.Database.update_data"><code class="name flex">
<span>def <span class="ident">update_data</span></span>(<span>self, new_data: pd.DataFrame)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace the existing data property with a new dataframe. All of the data is replaced.</p>
<p>This is useful if you need to do projections and then treat those projections as actual data
in a subsequent step in your analysis pipeline.</p>
<h3 id="arguments">Arguments</h3>
<p>new_data (pd.DataFrame): The new dataframe to use.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_data(self, new_data: pd.DataFrame):
    &#34;&#34;&#34;
    Replace the existing data property with a new dataframe. All of the data is replaced.

    This is useful if you need to do projections and then treat those projections as actual data
    in a subsequent step in your analysis pipeline.

   ### Arguments

    new_data (pd.DataFrame): The new dataframe to use.
    &#34;&#34;&#34;
    if not self._data.index.equals(new_data.index):
        raise Exception(&#34;The new database does not describe the same set of variables as the old database.&#34;)
    self._data = new_data</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="gcubed.base.Base" href="../base.html#gcubed.base.Base">Base</a></b></code>:
<ul class="hlist">
<li><code><a title="gcubed.base.Base.get_year_labels" href="../base.html#gcubed.base.Base.get_year_labels">get_year_labels</a></code></li>
<li><code><a title="gcubed.base.Base.load_data" href="../base.html#gcubed.base.Base.load_data">load_data</a></code></li>
<li><code><a title="gcubed.base.Base.zeros" href="../base.html#gcubed.base.Base.zeros">zeros</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="gcubed.data" href="index.html">gcubed.data</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="gcubed.data.database.Database" href="#gcubed.data.database.Database">Database</a></code></h4>
<ul class="">
<li><code><a title="gcubed.data.database.Database.base_year" href="#gcubed.data.database.Database.base_year">base_year</a></code></li>
<li><code><a title="gcubed.data.database.Database.configuration" href="#gcubed.data.database.Database.configuration">configuration</a></code></li>
<li><code><a title="gcubed.data.database.Database.data" href="#gcubed.data.database.Database.data">data</a></code></li>
<li><code><a title="gcubed.data.database.Database.export_to_csv" href="#gcubed.data.database.Database.export_to_csv">export_to_csv</a></code></li>
<li><code><a title="gcubed.data.database.Database.get_data" href="#gcubed.data.database.Database.get_data">get_data</a></code></li>
<li><code><a title="gcubed.data.database.Database.get_data_and_varmap_indices" href="#gcubed.data.database.Database.get_data_and_varmap_indices">get_data_and_varmap_indices</a></code></li>
<li><code><a title="gcubed.data.database.Database.get_data_and_varmap_indices_for_matching_variables" href="#gcubed.data.database.Database.get_data_and_varmap_indices_for_matching_variables">get_data_and_varmap_indices_for_matching_variables</a></code></li>
<li><code><a title="gcubed.data.database.Database.has_data" href="#gcubed.data.database.Database.has_data">has_data</a></code></li>
<li><code><a title="gcubed.data.database.Database.has_data_for_all_projection_years" href="#gcubed.data.database.Database.has_data_for_all_projection_years">has_data_for_all_projection_years</a></code></li>
<li><code><a title="gcubed.data.database.Database.rebase" href="#gcubed.data.database.Database.rebase">rebase</a></code></li>
<li><code><a title="gcubed.data.database.Database.rhs_vector_value" href="#gcubed.data.database.Database.rhs_vector_value">rhs_vector_value</a></code></li>
<li><code><a title="gcubed.data.database.Database.sym_data" href="#gcubed.data.database.Database.sym_data">sym_data</a></code></li>
<li><code><a title="gcubed.data.database.Database.update_data" href="#gcubed.data.database.Database.update_data">update_data</a></code></li>
<li><code><a title="gcubed.data.database.Database.variables" href="#gcubed.data.database.Database.variables">variables</a></code></li>
<li><code><a title="gcubed.data.database.Database.variables_count" href="#gcubed.data.database.Database.variables_count">variables_count</a></code></li>
<li><code><a title="gcubed.data.database.Database.years_column_names" href="#gcubed.data.database.Database.years_column_names">years_column_names</a></code></li>
<li><code><a title="gcubed.data.database.Database.years_count" href="#gcubed.data.database.Database.years_count">years_count</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>